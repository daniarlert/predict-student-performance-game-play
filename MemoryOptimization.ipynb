{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "This notebook contains a walkthrough of the memory optimization for the train dataset of this Kaggle's competition. The main goal is to reduce as much as posible the memory consumption of the dataset without losing any information by using the correct data types for each column.  "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Note that instead of pandas you can also use polars to load the data faster."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in ./.venv/lib/python3.11/site-packages (2.0.1)\n",
      "Requirement already satisfied: numpy in ./.venv/lib/python3.11/site-packages (1.24.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in ./.venv/lib/python3.11/site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in ./.venv/lib/python3.11/site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: tzdata>=2022.1 in ./.venv/lib/python3.11/site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: six>=1.5 in ./.venv/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install pandas numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to files\n",
    "test_csv_path = \"./data/test.csv\"\n",
    "train_csv_path = \"./data/train.csv\"\n",
    "train_labels_csv = \"./data/train_labels.csv\"\n",
    "\n",
    "sample_submission_csv = \"./data/sample_submission.csv\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Remember to check the data dictionary to get a better understanding of the data."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the dataset is quite large, we'll start by loading only a subset. This will allow us to perform the memory optimization faster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>session_id</th>\n",
       "      <th>elapsed_time</th>\n",
       "      <th>event_name</th>\n",
       "      <th>name</th>\n",
       "      <th>level</th>\n",
       "      <th>page</th>\n",
       "      <th>room_coor_x</th>\n",
       "      <th>room_coor_y</th>\n",
       "      <th>screen_coor_x</th>\n",
       "      <th>screen_coor_y</th>\n",
       "      <th>hover_duration</th>\n",
       "      <th>text</th>\n",
       "      <th>fqid</th>\n",
       "      <th>room_fqid</th>\n",
       "      <th>text_fqid</th>\n",
       "      <th>fullscreen</th>\n",
       "      <th>hq</th>\n",
       "      <th>music</th>\n",
       "      <th>level_group</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>index</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20090312431273200</td>\n",
       "      <td>0</td>\n",
       "      <td>cutscene_click</td>\n",
       "      <td>basic</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-413.991405</td>\n",
       "      <td>-159.314686</td>\n",
       "      <td>380.0</td>\n",
       "      <td>494.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>undefined</td>\n",
       "      <td>intro</td>\n",
       "      <td>tunic.historicalsociety.closet</td>\n",
       "      <td>tunic.historicalsociety.closet.intro</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0-4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20090312431273200</td>\n",
       "      <td>1323</td>\n",
       "      <td>person_click</td>\n",
       "      <td>basic</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-413.991405</td>\n",
       "      <td>-159.314686</td>\n",
       "      <td>380.0</td>\n",
       "      <td>494.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Whatcha doing over there, Jo?</td>\n",
       "      <td>gramps</td>\n",
       "      <td>tunic.historicalsociety.closet</td>\n",
       "      <td>tunic.historicalsociety.closet.gramps.intro_0_...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0-4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20090312431273200</td>\n",
       "      <td>831</td>\n",
       "      <td>person_click</td>\n",
       "      <td>basic</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-413.991405</td>\n",
       "      <td>-159.314686</td>\n",
       "      <td>380.0</td>\n",
       "      <td>494.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Just talking to Teddy.</td>\n",
       "      <td>gramps</td>\n",
       "      <td>tunic.historicalsociety.closet</td>\n",
       "      <td>tunic.historicalsociety.closet.gramps.intro_0_...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0-4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20090312431273200</td>\n",
       "      <td>1147</td>\n",
       "      <td>person_click</td>\n",
       "      <td>basic</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-413.991405</td>\n",
       "      <td>-159.314686</td>\n",
       "      <td>380.0</td>\n",
       "      <td>494.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>I gotta run to my meeting!</td>\n",
       "      <td>gramps</td>\n",
       "      <td>tunic.historicalsociety.closet</td>\n",
       "      <td>tunic.historicalsociety.closet.gramps.intro_0_...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0-4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20090312431273200</td>\n",
       "      <td>1863</td>\n",
       "      <td>person_click</td>\n",
       "      <td>basic</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-412.991405</td>\n",
       "      <td>-159.314686</td>\n",
       "      <td>381.0</td>\n",
       "      <td>494.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Can I come, Gramps?</td>\n",
       "      <td>gramps</td>\n",
       "      <td>tunic.historicalsociety.closet</td>\n",
       "      <td>tunic.historicalsociety.closet.gramps.intro_0_...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0-4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              session_id  elapsed_time      event_name   name  level  page   \n",
       "index                                                                        \n",
       "0      20090312431273200             0  cutscene_click  basic      0   NaN  \\\n",
       "1      20090312431273200          1323    person_click  basic      0   NaN   \n",
       "2      20090312431273200           831    person_click  basic      0   NaN   \n",
       "3      20090312431273200          1147    person_click  basic      0   NaN   \n",
       "4      20090312431273200          1863    person_click  basic      0   NaN   \n",
       "\n",
       "       room_coor_x  room_coor_y  screen_coor_x  screen_coor_y  hover_duration   \n",
       "index                                                                           \n",
       "0      -413.991405  -159.314686          380.0          494.0             NaN  \\\n",
       "1      -413.991405  -159.314686          380.0          494.0             NaN   \n",
       "2      -413.991405  -159.314686          380.0          494.0             NaN   \n",
       "3      -413.991405  -159.314686          380.0          494.0             NaN   \n",
       "4      -412.991405  -159.314686          381.0          494.0             NaN   \n",
       "\n",
       "                                text    fqid                       room_fqid   \n",
       "index                                                                          \n",
       "0                          undefined   intro  tunic.historicalsociety.closet  \\\n",
       "1      Whatcha doing over there, Jo?  gramps  tunic.historicalsociety.closet   \n",
       "2             Just talking to Teddy.  gramps  tunic.historicalsociety.closet   \n",
       "3         I gotta run to my meeting!  gramps  tunic.historicalsociety.closet   \n",
       "4                Can I come, Gramps?  gramps  tunic.historicalsociety.closet   \n",
       "\n",
       "                                               text_fqid  fullscreen  hq   \n",
       "index                                                                      \n",
       "0                   tunic.historicalsociety.closet.intro           0   0  \\\n",
       "1      tunic.historicalsociety.closet.gramps.intro_0_...           0   0   \n",
       "2      tunic.historicalsociety.closet.gramps.intro_0_...           0   0   \n",
       "3      tunic.historicalsociety.closet.gramps.intro_0_...           0   0   \n",
       "4      tunic.historicalsociety.closet.gramps.intro_0_...           0   0   \n",
       "\n",
       "       music level_group  \n",
       "index                     \n",
       "0          1         0-4  \n",
       "1          1         0-4  \n",
       "2          1         0-4  \n",
       "3          1         0-4  \n",
       "4          1         0-4  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read a subset of the train dataset\n",
    "train_df = pd.read_csv(train_csv_path, index_col=\"index\", nrows=10_000)\n",
    "train_df.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Memory optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 19)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the shape of the train dataset\n",
    "train_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index              80000\n",
       "session_id         80000\n",
       "elapsed_time       80000\n",
       "event_name        700443\n",
       "name              638871\n",
       "level              80000\n",
       "page               80000\n",
       "room_coor_x        80000\n",
       "room_coor_y        80000\n",
       "screen_coor_x      80000\n",
       "screen_coor_y      80000\n",
       "hover_duration     80000\n",
       "text              525518\n",
       "fqid              567025\n",
       "room_fqid         847275\n",
       "text_fqid         569413\n",
       "fullscreen         80000\n",
       "hq                 80000\n",
       "music              80000\n",
       "level_group       614050\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the memory usage of the train dataset subset\n",
    "train_df.memory_usage(deep=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.247683525085449"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the memory usage of the train dataset subset in mb\n",
    "train_df.memory_usage(deep=True).sum() / 1024**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['session_id', 'elapsed_time', 'event_name', 'name', 'level', 'page',\n",
       "       'room_coor_x', 'room_coor_y', 'screen_coor_x', 'screen_coor_y',\n",
       "       'hover_duration', 'text', 'fqid', 'room_fqid', 'text_fqid',\n",
       "       'fullscreen', 'hq', 'music', 'level_group'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Columns names\n",
    "train_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "session_id          int64\n",
       "elapsed_time        int64\n",
       "event_name         object\n",
       "name               object\n",
       "level               int64\n",
       "page              float64\n",
       "room_coor_x       float64\n",
       "room_coor_y       float64\n",
       "screen_coor_x     float64\n",
       "screen_coor_y     float64\n",
       "hover_duration    float64\n",
       "text               object\n",
       "fqid               object\n",
       "room_fqid          object\n",
       "text_fqid          object\n",
       "fullscreen          int64\n",
       "hq                  int64\n",
       "music               int64\n",
       "level_group        object\n",
       "dtype: object"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the data types of the train dataset subset\n",
    "train_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "session_id           0\n",
       "elapsed_time         0\n",
       "event_name           0\n",
       "name                 0\n",
       "level                0\n",
       "page              9766\n",
       "room_coor_x       1015\n",
       "room_coor_y       1015\n",
       "screen_coor_x     1015\n",
       "screen_coor_y     1015\n",
       "hover_duration    9013\n",
       "text              6368\n",
       "fqid              3031\n",
       "room_fqid            0\n",
       "text_fqid         6368\n",
       "fullscreen           0\n",
       "hq                   0\n",
       "music                0\n",
       "level_group          0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Number of nan values in each column\n",
    "train_df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "session_id          10\n",
       "elapsed_time      9980\n",
       "event_name          11\n",
       "name                 6\n",
       "level               23\n",
       "page                 7\n",
       "room_coor_x       8669\n",
       "room_coor_y       7243\n",
       "screen_coor_x     1011\n",
       "screen_coor_y      704\n",
       "hover_duration     490\n",
       "text               522\n",
       "fqid               118\n",
       "room_fqid           19\n",
       "text_fqid          104\n",
       "fullscreen           2\n",
       "hq                   2\n",
       "music                2\n",
       "level_group          3\n",
       "dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Number of unique values in each column\n",
    "train_df.nunique()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since some columns like `fullscreen`, `hq` and `music` are binary values (0, 1), we can use the `bool` type instead of `int64`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df[\"fullscreen\"] = train_df[\"fullscreen\"].astype(\"bool\")\n",
    "train_df[\"hq\"] = train_df[\"hq\"].astype(\"bool\")\n",
    "train_df[\"music\"] = train_df[\"music\"].astype(\"bool\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "event_name\n",
       "navigate_click        4152\n",
       "person_click          2256\n",
       "cutscene_click        1035\n",
       "object_click           736\n",
       "map_hover              539\n",
       "object_hover           448\n",
       "notification_click     262\n",
       "notebook_click         234\n",
       "map_click              231\n",
       "observation_click       79\n",
       "checkpoint              28\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the event_name column\n",
    "train_df[\"event_name\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "name\n",
       "basic        4855\n",
       "undefined    4745\n",
       "close         291\n",
       "open          103\n",
       "prev            4\n",
       "next            2\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the name column\n",
    "train_df[\"name\"].value_counts()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `event_name` and `name` columns are categorical values, so we can use the `category` type instead of `object`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df[\"event_name\"] = train_df[\"event_name\"].astype(\"category\")\n",
    "train_df[\"name\"] = train_df[\"name\"].astype(\"category\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 22)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the level column range of values\n",
    "train_df[\"level\"].min(), train_df[\"level\"].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Since the range of the level column is small, we can convert it to int8\n",
    "train_df[\"level\"] = train_df[\"level\"].astype(\"int8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "page\n",
       "6.0    57\n",
       "5.0    44\n",
       "1.0    38\n",
       "4.0    35\n",
       "0.0    31\n",
       "3.0    22\n",
       "2.0     7\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the page column\n",
    "train_df[\"page\"].value_counts()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As with the `level` column, we can use a smaller integer type for it. In this case, we'll use the `Int8` due to the presence of `NaN` values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df[\"page\"] = train_df[\"page\"].astype(\"Int8\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the data dictionary we can see that the `level_group` is a categorical value, so we can use the `category` type. But since the order in this case is importart, first we'll create a new category type with the correct order and then we'll use it to convert the column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "level_group_cat_type = pd.CategoricalDtype(\n",
    "    categories=[\"0-4\", \"5-12\", \"13-22\"], ordered=True\n",
    ")\n",
    "train_df[\"level_group\"] = train_df[\"level_group\"].astype(level_group_cat_type)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's perform a quick check of some columns like `fqid`, `room_fqid`, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "fqid\n",
       "worker                          661\n",
       "gramps                          451\n",
       "archivist                       421\n",
       "toentry                         307\n",
       "wells                           278\n",
       "                               ... \n",
       "reader.paper0.prev                2\n",
       "reader.paper2.prev                2\n",
       "tocloset                          2\n",
       "reader.paper1.prev                1\n",
       "journals_flag.pic_1_old.next      1\n",
       "Name: count, Length: 118, dtype: int64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df[\"fqid\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "room_fqid\n",
       "tunic.historicalsociety.entry              1517\n",
       "tunic.wildlife.center                      1055\n",
       "tunic.historicalsociety.cage                786\n",
       "tunic.library.frontdesk                     772\n",
       "tunic.historicalsociety.stacks              705\n",
       "tunic.historicalsociety.frontdesk           703\n",
       "tunic.historicalsociety.closet_dirty        603\n",
       "tunic.humanecology.frontdesk                499\n",
       "tunic.kohlcenter.halloffame                 479\n",
       "tunic.historicalsociety.basement            439\n",
       "tunic.drycleaner.frontdesk                  367\n",
       "tunic.historicalsociety.collection          354\n",
       "tunic.historicalsociety.closet              339\n",
       "tunic.library.microfiche                    327\n",
       "tunic.flaghouse.entry                       313\n",
       "tunic.capitol_2.hall                        274\n",
       "tunic.capitol_1.hall                        191\n",
       "tunic.historicalsociety.collection_flag     176\n",
       "tunic.capitol_0.hall                        101\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df[\"room_fqid\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "text_fqid\n",
       "tunic.historicalsociety.cage.confrontation                     212\n",
       "tunic.historicalsociety.entry.groupconvo                       184\n",
       "tunic.wildlife.center.crane_ranger.crane                       164\n",
       "tunic.historicalsociety.frontdesk.archivist.newspaper          164\n",
       "tunic.historicalsociety.frontdesk.archivist.have_glass         156\n",
       "                                                              ... \n",
       "tunic.capitol_2.hall.chap4_finale_c                              1\n",
       "tunic.capitol_1.hall.boss.writeitup                              1\n",
       "tunic.capitol_1.hall.chap2_finale_c                              1\n",
       "tunic.humanecology.frontdesk.block_0                             1\n",
       "tunic.historicalsociety.frontdesk.archivist.newspaper_recap      1\n",
       "Name: count, Length: 104, dtype: int64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df[\"text_fqid\"].value_counts()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, we can convert this columns to a category type without the loss of any information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df[\"fqid\"] = train_df[\"fqid\"].astype(\"category\")\n",
    "train_df[\"room_fqid\"] = train_df[\"room_fqid\"].astype(\"category\")\n",
    "train_df[\"text_fqid\"] = train_df[\"text_fqid\"].astype(\"category\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Columns like `room_coor_x`, `room_coor_y`, `screen_coor_x`, `screen_coor_y` and `hover_duration` have a float64 type but looking at the data we can see that maybe they could be converted to float32 without a loss in information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1234.4698376483232"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df[\"room_coor_x\"].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "484.99533347049936"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df[\"room_coor_y\"].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1196.0"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df[\"screen_coor_x\"].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "898.0"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df[\"screen_coor_y\"].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26695.0"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df[\"hover_duration\"].max()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "None of the columns needs the precision of a `float64`, so we can convert them to `float32` without losing any information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df[\"room_coor_x\"] = train_df[\"room_coor_x\"].astype(\"float32\")\n",
    "train_df[\"room_coor_y\"] = train_df[\"room_coor_y\"].astype(\"float32\")\n",
    "train_df[\"screen_coor_x\"] = train_df[\"screen_coor_x\"].astype(\"float32\")\n",
    "train_df[\"screen_coor_y\"] = train_df[\"screen_coor_y\"].astype(\"float32\")\n",
    "train_df[\"hover_duration\"] = train_df[\"hover_duration\"].astype(\"float32\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `elapsed_time` columns contains very large values, so we will leave it as an `int64` type. Also, we have to remember that we are working with a subset of the data, so the values in the full dataset could be even larger."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we can convert the `text` columns to a category type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df[\"text\"] = train_df[\"text\"].astype(\"str\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, let's check the memory usage again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index              80000\n",
       "session_id         80000\n",
       "elapsed_time       80000\n",
       "event_name         11068\n",
       "name               10545\n",
       "level              10000\n",
       "page               20000\n",
       "room_coor_x        40000\n",
       "room_coor_y        40000\n",
       "screen_coor_x      40000\n",
       "screen_coor_y      40000\n",
       "hover_duration     40000\n",
       "text              703822\n",
       "fqid               22548\n",
       "room_fqid          12160\n",
       "text_fqid          24655\n",
       "fullscreen         10000\n",
       "hq                 10000\n",
       "music              10000\n",
       "level_group        10291\n",
       "dtype: int64"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.memory_usage(deep=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.235093116760254"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the memory usage of the train dataset subset in mb\n",
    "train_df.memory_usage(deep=True).sum() / 1024**2"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have reduced the memory usage drastically by just converting some columns to categorical types and the numerical values to more efficient types for the data ranges they contain. This will allow us to load the full dataset later more efficiently and to be able to iterate faster over the data when needed.  "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the full dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(\n",
    "    train_csv_path,\n",
    "    index_col=\"index\",\n",
    "    dtype={\n",
    "        \"session_id\": \"int64\",\n",
    "        \"elapsed_time\": \"int64\",\n",
    "        \"event_name\": \"category\",\n",
    "        \"name\": \"category\",\n",
    "        \"level\": \"int8\",\n",
    "        \"page\": \"Int8\",\n",
    "        \"room_coor_x\": \"float32\",\n",
    "        \"room_coor_y\": \"float32\",\n",
    "        \"screen_coor_x\": \"float32\",\n",
    "        \"screen_coor_y\": \"float32\",\n",
    "        \"hover_duration\": \"float32\",\n",
    "        \"text\": \"str\",\n",
    "        \"fqid\": \"category\",\n",
    "        \"room_fqid\": \"category\",\n",
    "        \"text_fqid\": \"category\",\n",
    "        \"fullscreen\": \"bool\",\n",
    "        \"hq\": \"bool\",\n",
    "        \"music\": \"bool\",\n",
    "        \"level_group\": level_group_cat_type,\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2749.636650085449"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the memory usage of the full train dataset in mb\n",
    "train_df.memory_usage(deep=True).sum() / 1024**2"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that instead of using `bool` for the binary columns, we can also use `int8`."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
