{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install pandas numpy scikit-learn xgboost matplotlib seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import gc\n",
    "import jo_wilder\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import KFold, GroupKFold\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup matplotlib\n",
    "%matplotlib inline"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to files\n",
    "test_csv_path = \"./data/test.csv\"\n",
    "train_csv_path = \"./data/train.csv\"\n",
    "target_labels_csv = \"./data/train_labels.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "level_group_cat_type = pd.CategoricalDtype(\n",
    "    categories=[\"0-4\", \"5-12\", \"13-22\"], ordered=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(\n",
    "    train_csv_path,\n",
    "    index_col=\"index\",\n",
    "    dtype={\n",
    "        \"session_id\": \"int64\",\n",
    "        \"elapsed_time\": \"int32\",\n",
    "        \"event_name\": \"category\",\n",
    "        \"name\": \"category\",\n",
    "        \"level\": \"int8\",\n",
    "        \"page\": \"Int8\",\n",
    "        \"room_coor_x\": \"float32\",\n",
    "        \"room_coor_y\": \"float32\",\n",
    "        \"screen_coor_x\": \"float32\",\n",
    "        \"screen_coor_y\": \"float32\",\n",
    "        \"hover_duration\": \"float32\",\n",
    "        \"text\": \"str\",\n",
    "        \"fqid\": \"category\",\n",
    "        \"room_fqid\": \"category\",\n",
    "        \"text_fqid\": \"category\",\n",
    "        \"fullscreen\": \"int8\",\n",
    "        \"hq\": \"int8\",\n",
    "        \"music\": \"int8\",\n",
    "        \"level_group\": level_group_cat_type,\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_df = pd.read_csv(target_labels_csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_df[\"session\"] = target_df.session_id.apply(lambda x: int(x.split(\"_\")[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_df[\"q\"] = target_df.session_id.apply(lambda x: int(x.split(\"_\")[-1][1:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_df[\"correct\"] = target_df[\"correct\"].astype(\"int8\")\n",
    "target_df[\"q\"] = target_df[\"q\"].astype(\"int8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_df.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_cols = [\"event_name\", \"fqid\", \"room_fqid\", \"text\"]\n",
    "numerical_cols = [\n",
    "    \"elapsed_time\",\n",
    "    \"level\",\n",
    "    \"page\",\n",
    "    \"room_coor_x\",\n",
    "    \"room_coor_y\",\n",
    "    \"screen_coor_x\",\n",
    "    \"screen_coor_y\",\n",
    "    \"hover_duration\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "events = train_df.event_name.unique().tolist()\n",
    "events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_engineer(train_df):\n",
    "    dfs = []\n",
    "\n",
    "    for c in categorical_cols:\n",
    "        tmp = train_df.groupby([\"session_id\", \"level_group\"])[c].agg(\"nunique\")\n",
    "        tmp.name = tmp.name + \"_nunique\"\n",
    "\n",
    "        dfs.append(tmp)\n",
    "\n",
    "    for c in numerical_cols:\n",
    "        tmp = train_df.groupby([\"session_id\", \"level_group\"])[c].agg(\"mean\")\n",
    "        tmp.name = tmp.name + \"_mean\"\n",
    "\n",
    "        dfs.append(tmp)\n",
    "\n",
    "    for c in numerical_cols:\n",
    "        tmp = train_df.groupby([\"session_id\", \"level_group\"])[c].agg(\"std\")\n",
    "        tmp.name = tmp.name + \"_std\"\n",
    "\n",
    "        dfs.append(tmp)\n",
    "\n",
    "    for c in events:\n",
    "        train_df[c] = (train_df.event_name == c).astype(\"int8\")\n",
    "\n",
    "    for c in events + [\"elapsed_time\"]:\n",
    "        tmp = train_df.groupby([\"session_id\", \"level_group\"])[c].agg(\"sum\")\n",
    "        tmp.name = tmp.name + \"_sum\"\n",
    "\n",
    "        dfs.append(tmp)\n",
    "\n",
    "    train_df = train_df.drop(events, axis=1)\n",
    "\n",
    "    df = pd.concat(dfs, axis=1)\n",
    "    df = df.fillna(-1)\n",
    "    df = df.reset_index()\n",
    "    df = df.set_index(\"session_id\")\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = feature_engineer(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del train_df\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [c for c in df.columns if c != \"level_group\"]\n",
    "users = df.index.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gkf = GroupKFold(n_splits=5)\n",
    "oof = pd.DataFrame(\n",
    "    data=np.zeros((len(users), 18)),\n",
    "    index=users,\n",
    ")\n",
    "models = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, (train_index, test_index) in enumerate(gkf.split(X=df, groups=df.index)):\n",
    "    print(\"#\" * 25)\n",
    "    print(\"### Fold\", i + 1)\n",
    "    print(\"#\" * 25)\n",
    "\n",
    "    xgb_params = {\n",
    "        \"objective\": \"binary:logistic\",\n",
    "        \"eval_metric\": \"logloss\",\n",
    "        \"learning_rate\": 0.05,\n",
    "        \"max_depth\": 4,\n",
    "        \"n_estimators\": 1000,\n",
    "        \"early_stopping_rounds\": 50,\n",
    "        \"tree_method\": \"hist\",\n",
    "        \"subsample\": 0.8,\n",
    "        \"colsample_bytree\": 0.4,\n",
    "        \"use_label_encoder\": False,\n",
    "    }\n",
    "\n",
    "    for t in range(1, 19):\n",
    "        if t <= 3:\n",
    "            grp = \"0-4\"\n",
    "        elif t <= 13:\n",
    "            grp = \"5-12\"\n",
    "        elif t <= 22:\n",
    "            grp = \"13-22\"\n",
    "\n",
    "        # TRAIN DATA\n",
    "        train_x = df.iloc[train_index]\n",
    "        train_x = train_x.loc[train_x.level_group == grp]\n",
    "        train_users = train_x.index.values\n",
    "        train_y = target_df.loc[target_df.q == t].set_index(\"session\").loc[train_users]\n",
    "\n",
    "        # VALID DATA\n",
    "        valid_x = df.iloc[test_index]\n",
    "        valid_x = valid_x.loc[valid_x.level_group == grp]\n",
    "        valid_users = valid_x.index.values\n",
    "        valid_y = target_df.loc[target_df.q == t].set_index(\"session\").loc[valid_users]\n",
    "\n",
    "        # TRAIN MODEL\n",
    "        clf = XGBClassifier(**xgb_params)\n",
    "        clf.fit(\n",
    "            train_x[features].astype(\"float32\"),\n",
    "            train_y[\"correct\"],\n",
    "            eval_set=[(valid_x[features].astype(\"float32\"), valid_y[\"correct\"])],\n",
    "            verbose=0,\n",
    "        )\n",
    "        print(f\"{t}({clf.best_ntree_limit}), \", end=\"\")\n",
    "\n",
    "        # SAVE MODEL, PREDICT VALID OOF\n",
    "        models[f\"{grp}_{t}\"] = clf\n",
    "        oof.loc[valid_users, t - 1] = clf.predict_proba(\n",
    "            valid_x[features].astype(\"float32\")\n",
    "        )[:, 1]\n",
    "\n",
    "    print()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CV score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "true = oof.copy()\n",
    "for k in range(18):\n",
    "    # GET TRUE LABELS\n",
    "    tmp = target_df.loc[target_df.q == k + 1].set_index(\"session\").loc[users]\n",
    "    true[k] = tmp.correct.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = []\n",
    "thresholds = []\n",
    "\n",
    "best_score = 0\n",
    "best_threshold = 0\n",
    "\n",
    "for threshold in np.arange(0.4, 0.81, 0.01):\n",
    "    print(f\"{threshold:.02f}, \", end=\"\")\n",
    "    preds = (oof.values.reshape((-1)) > threshold).astype(\"int\")\n",
    "    m = f1_score(true.values.reshape((-1)), preds, average=\"macro\")\n",
    "    scores.append(m)\n",
    "    thresholds.append(threshold)\n",
    "    if m > best_score:\n",
    "        best_score = m\n",
    "        best_threshold = threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 5))\n",
    "plt.plot(thresholds, scores, \"-o\", color=\"blue\")\n",
    "plt.scatter([best_threshold], [best_score], color=\"blue\", s=300, alpha=1)\n",
    "plt.xlabel(\"Threshold\", size=14)\n",
    "plt.ylabel(\"Validation F1 Score\", size=14)\n",
    "plt.title(\n",
    "    f\"Threshold vs. F1_Score with Best F1_Score = {best_score:.3f} at Best Threshold = {best_threshold:.3}\",\n",
    "    size=18,\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"When using optimal threshold...\")\n",
    "for k in range(18):\n",
    "    # COMPUTE F1 SCORE PER QUESTION\n",
    "    m = f1_score(\n",
    "        true[k].values, (oof[k].values > best_threshold).astype(\"int\"), average=\"macro\"\n",
    "    )\n",
    "    print(f\"Q{k}: F1 =\", m)\n",
    "\n",
    "# COMPUTE F1 SCORE OVERALL\n",
    "m = f1_score(\n",
    "    true.values.reshape((-1)),\n",
    "    (oof.values.reshape((-1)) > best_threshold).astype(\"int\"),\n",
    "    average=\"macro\",\n",
    ")\n",
    "print(\"==> Overall F1 =\", m)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Infer test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create environment\n",
    "env = jo_wilder.make_env()\n",
    "iter_test = env.iter_test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clear memory\n",
    "del target_df, df, oof, true\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "limits = {\"0-4\": (1, 4), \"5-12\": (4, 14), \"13-22\": (14, 19)}\n",
    "\n",
    "for test, sample_submission in iter_test:\n",
    "    # FEATURE ENGINEER TEST DATA\n",
    "    df = feature_engineer(test)\n",
    "\n",
    "    # INFER TEST DATA\n",
    "    grp = test.level_group.values[0]\n",
    "    a, b = limits[grp]\n",
    "    for t in range(a, b):\n",
    "        clf = models[f\"{grp}_{t}\"]\n",
    "        p = clf.predict_proba(df[features].astype(\"float32\"))[0, 1]\n",
    "        mask = sample_submission.session_id.str.contains(f\"q{t}\")\n",
    "        sample_submission.loc[mask, \"correct\"] = int(p > best_threshold)\n",
    "\n",
    "    env.predict(sample_submission)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"submission.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.correct.mean()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
